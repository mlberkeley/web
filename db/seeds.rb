# This file should contain all the record creation needed to seed the database with its default values.
# The data can then be loaded with the rake db:seed (or created alongside the db with db:setup).
Project.create(name: "Open Brain", tag: "research", description: "In this project, we introduce a new framework and philosophy for recurrent neurocomputation. By requiring that all neurons act asynchrynously and independently, we introduce a new metric for evaluating the universal intelligence of continuous time agents. We proved representation and universal approximation results in this context which lead to a set of learning rules in the spirit of John Conway's game of life. Finally evaluate this framework against different intelligent agent algorithms by implementing an approximate universal intelligence measure for agents embedded in turing computable environments in Minecraft, BF, and a variety of other reference machines.", img_url:"https://s3-us-west-1.amazonaws.com/mlberkeley/open_brain.png")
Project.create(name: "Deep Active Learning Learning", tag: "research", description: "A lot of general machine learning models rely heavily on labeled data. A lot of unlabeled data is plentiful and cheap e.g. images, speech samples, documents from the web. But in practice, labeling data can be expensive. In active learning, the learner queries the user for labels. Since the learner chooses examples, the number of examples to learn a concept can be much lower [Wikipedia]. In seperable problems, it is theoretically possible to achieve exponential improvement in label complexity. Active Learning heavily uses exploration and exploitation to search through its search space. For example, Hieraracical active learning [ICML ’08] is very similar to Monte Carlo Tree Search, and even involves a backpropogation of nodes. Inspired by recent advances in integrating deep reinforcement learning in Monte Carlo Tree Search and Go [Alpha Go, Silver et.al. 2016], we seek to apply deep reinforcement learning to the general problem of Active Learning.", img_url: "https://s3-us-west-1.amazonaws.com/mlberkeley/deep_active.png")
Project.create(name: "Parameter Reduction using Generalized Neural Networks", tag: "research", description: "In this paper, we generalize ANNs to infinite dimensional Banach spaces by developing a practical analog to the feedforward propagation algorithm. Using this new class of algorithms, GANN, we prove a new universal approximation theorem for bounded linear operators and show that representation of weights by samples from a multivariate weight polynomial can drastically reduce the dimensionality of a learning problem. Lastly, we give a practical implementation of the error back-propagation algorithm in this space for the classification of continuous data.", img_url: "https://s3-us-west-1.amazonaws.com/mlberkeley/neural_networks.png")
Project.create(name: "Improving Music Recommendation", tag: "research", description: "The objective of this research project is to improve content-based music recommendation by featurizing a song’s stems and digital audio workstation settings. This proprietary data is difficult to obtain from record labels, so our team’s workaround is to reverse engineer the stems by passing short clips of songs from the Million Song Dataset into operator neural nets, which allow for continuous functions as input. To test our stem data against the corresponding song clips, we are comparing content-based versus collaborative filtering methods, and manually checking for the similarity of songs in playlists generated by Locality-Sensitive Hashing (LSH).", img_url: "https://s3-us-west-1.amazonaws.com/mlberkeley/music.png")
Project.create(name: "Genetic Algorithms for Modelling Experimental Data", tag: "research",description: "The purpose of this project is to generate equations to model experimental data, with emphasis on both minimizing error and maintaining parsimony. The equations should take a form that conveys the intuition behind the physical system being analyzed. The space of equations explored can be as large as ~10120, making conventional estimation methods intractable. We explore the possibility of exploring this space by expressing equations as trees, and using mutations inspired by biological evolution to find local minima. Preliminary results can successfully fit quadratic systems (up to a constant bias), and evidence exists that the algorithm maintains equation diversity while steadily increasing fitness.", img_url: "https://s3-us-west-1.amazonaws.com/mlberkeley/genetic_alg.png")
Project.create(name: "Grand Rounds", tag: "industry", description: "Working with medicare data, our team was tasked to explore and discover anomalies and trends in the data. In particular, we were charged with figuring out the best way to featurize patients and physicians to then better match the two. For example, a patient with a certain illness should be matched with a physician who has great experience diagnosis this illness and performing the correct procedures for that patient. With our team of about 10, we were able to do first order statistics and generate primitive cost and patient models with the data.", img_url: "https://s3-us-west-1.amazonaws.com/mlberkeley/grand_round.png")
Project.create(name: "Quantiacs", tag: "industry", description: "A Machine Learning at Berkeley project team worked with Quantiacs to develop trading systems and algorithms utilizing Quantiacs’ quantitative trading platform. With the help of Quantiacs, project team members built successful algorithms on the platform. We found that that their platform was very intuitive to use and discovered practical limitations of certain learning algorithms.", img_url: "https://s3-us-west-1.amazonaws.com/mlberkeley/quantiacs.png")
Project.create(name: "H2O.ai", tag: "industry", description: "The H2O.ai project was to demonstrate the power of H2O’s Sparkling Water framework for machine learning. To this end, the team decided to take on the task of predicting the approximate score of Reddit comments given a comment’s metadata, such as subreddit, timestamp, parent thread, etc., as well as the contents of the comment itself. The team employed a multitude of natural language processing techniques and machine learning algorithms to parse the comment and regress on the data, and later constructed a superlearner that was optimized across the ensemble of algorithms to further improve prediction. At the end of the project, the team achieved outstanding results, with their model being able to differentiate higher scoring comments from lower scoring comments with nearly 99% accuracy.", img_url: "https://s3-us-west-1.amazonaws.com/mlberkeley/h2o.png")
AdminUser.create!(email: 'admin@berkeley.edu', password: 'password', password_confirmation: 'password')
